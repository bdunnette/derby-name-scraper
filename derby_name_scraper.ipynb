{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "derby_name_scraper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMO1Y1Qj5LWt"
      },
      "source": [
        "Generating [derby names](https://en.wikipedia.org/wiki/Roller_derby#Derby_names) from publicly-accessible lists\n",
        "\n",
        "Adapted from Max Woolf's notebook: https://drive.google.com/file/d/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK/view?usp=sharing\n",
        "\n",
        "Inspired by Janelle Shane's blog post: http://aiweirdness.com/post/174466734677/neural-network-generated-roller-derby-names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxMLEnyTe7B_"
      },
      "source": [
        "import string\n",
        "import random\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import concurrent.futures\n",
        "\n",
        "from google.colab import files\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a49OXrue_NW"
      },
      "source": [
        "training_file = Path(\"derby_names.txt\")\n",
        "model_name = 'derbynames' "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51mDvze3U621"
      },
      "source": [
        "session = requests.Session()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZn313h1VH3M",
        "outputId": "7f91ec51-c4d1-4e1f-bd0c-1f028647a01a"
      },
      "source": [
        "url = \"http://www.derbyrollcall.com/everyone\"\n",
        "print(\"Downloading names from %s\" % url)\n",
        "drc_df = pd.concat(pd.read_html(url))\n",
        "drc_df = drc_df.rename(columns={\"#\":\"Number\"})\n",
        "drc_df['url'] = url\n",
        "drc_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading names from http://www.derbyrollcall.com/everyone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0o8T_WdCy7X"
      },
      "source": [
        "url = \"https://www.twoevils.org/rollergirls/\"\n",
        "print(\"Downloading names from %s\" % url)\n",
        "twoevils_df = pd.read_html(url,skiprows=1)[0]\n",
        "twoevils_df.columns = [h.replace('Skater','').strip() for h in twoevils_df.iloc[0]]\n",
        "twoevils_df = twoevils_df.rename(columns={'Date Added':'Registered'})\n",
        "twoevils_df = twoevils_df.iloc[1:-1 , :].dropna(how='all')\n",
        "twoevils_df['url'] = url\n",
        "twoevils_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boZuLM56VHv1"
      },
      "source": [
        "initial_letters = string.ascii_uppercase + string.digits + string.punctuation\n",
        "rdr_df = pd.DataFrame()\n",
        "\n",
        "def get_page_names(initial_letter, timeout=30):\n",
        "    temp_names = []\n",
        "    url = \"https://rollerderbyroster.com/view-names/?ini={}\".format(letter)\n",
        "    print(\"Downloading names from {}\".format(url))\n",
        "    try:\n",
        "      response = session.get(url=url, timeout=timeout)\n",
        "      r = session.get(url)\n",
        "      soup = BeautifulSoup(r.text, \"lxml\")\n",
        "      rows = soup.find_all('ul')\n",
        "      # Use only last unordered list - this is where names are!\n",
        "      for idx, li in enumerate(rows[-1]):\n",
        "        # Name should be the text of the link within the list item\n",
        "        name = li.find('a').get_text()\n",
        "        temp_names.append(name)\n",
        "    except requests.Timeout:\n",
        "      print(\"Timeout!\")\n",
        "      pass\n",
        "    return temp_names\n",
        "\n",
        "for letter in initial_letters:\n",
        "  try:\n",
        "    temp_names = get_page_names(initial_letter=letter)\n",
        "    temp_df = pd.DataFrame(data={'Name':temp_names, 'url':url})\n",
        "    rdr_df.append(temp_df)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    pass\n",
        "\n",
        "rdr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cWhdy6cZLwD"
      },
      "source": [
        "url='https://resources.wftda.org/officiating/roller-derby-certification-program-for-officials/roster-of-certified-officials/'\n",
        "print(\"Downloading names from {}\".format(url))\n",
        "session.headers.update({'User-Agent':'Mozilla/5.0'})\n",
        "r = session.get(url)\n",
        "soup = BeautifulSoup(r.text, \"lxml\")\n",
        "rows = soup.find_all('h5')\n",
        "urls = [r.find('a')['href'] for r in rows]\n",
        "names = [r.find('a').get_text() for r in rows]\n",
        "wftda_df = pd.DataFrame({'Name':names,'url':urls})\n",
        "wftda_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gNRhesUVAT0"
      },
      "source": [
        "name_df = pd.concat([twoevils_df,drc_df,rdr_df,wftda_df],ignore_index=True)\n",
        "# remove parenthetical phrases from names - eg \"(cleared)\"\n",
        "name_df['Name'] = name_df['Name'].str.replace(r\"\\([^()]*\\)\", \"\").str.strip()\n",
        "name_df = name_df.loc[name_df['Name'].str.len()>1]\n",
        "name_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file=Path('derby_names.csv')\n",
        "name_df.drop_duplicates().sort_values(by=['Name']).to_csv(csv_file,index=False)\n",
        "files.download(csv_file)"
      ],
      "metadata": {
        "id": "Lg4NjQZLBTQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J34siawKlWg7"
      },
      "source": [
        "names_only = name_df[['Name']].drop_duplicates().sort_values(by=['Name'])\n",
        "names_only.to_csv('derby_names.txt',index=False,header=False)\n",
        "files.download('derby_names.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIpLjbHrljl-"
      },
      "source": [
        "numbers = name_df[['Number']].drop_duplicates().sort_values(by=['Number'])\n",
        "numbers.to_csv('derby_numbers.txt',index=False,header=False)\n",
        "files.download('derby_numbers.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names_numbers = name_df[~name_df['Number'].isna()][['Name','Number']].drop_duplicates().sort_values(by=['Name','Number'])\n",
        "names_numbers.to_csv('derby_names_numbers.tsv',index=False,header=False,sep='\\t')\n",
        "files.download('derby_names_numbers.tsv')"
      ],
      "metadata": {
        "id": "ls8p0QWf-ugI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}